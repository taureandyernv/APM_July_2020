{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jS7jHZQ5cAAx"
   },
   "source": [
    "# Compare RAPIDS Dimension Reduction Techniques\n",
    "Heavily influenced by https://umap-learn.readthedocs.io/en/latest/auto_examples/plot_algorithm_comparison.html#sphx-glr-auto-examples-plot-algorithm-comparison-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UFzOYVscAA2"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IuUCjLzcAA3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import dask_cudf\n",
    "import cudf\n",
    "import cuml\n",
    "import pandas as pd\n",
    "from sklearn import datasets, decomposition, manifold, preprocessing\n",
    "from colorsys import hsv_to_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ote465YNcAA7"
   },
   "source": [
    "## Prepare and size your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFn82ilMcAA8"
   },
   "source": [
    "Things to note about the datasets:\n",
    "\n",
    "- Blobs: A set of five gaussian blobs in 10 dimensional space. This should be a prototypical example of something that should clearly separate even in a reduced dimension space.\n",
    "- Iris: a classic small dataset with one distinct class and two classes that are not clearly separated.\n",
    "- Digits: handwritten digits – ideally different digit classes should form distinct groups. Due to the nature of handwriting digits may have several forms (crossed or uncrossed sevens, capped or straight line oes, etc.)\n",
    "- Wine: wine characteristics ideally used for a toy regression. Ultimately the data is essentially one dimensional in nature.\n",
    "- Swiss Roll: data is essentially a rectangle, but has been “rolled up” like a swiss roll in three dimensional space. Ideally a dimension reduction technique should be able to “unroll” it. The data has been coloured according to one dimension of the rectangle, so should form a rectangle of smooth color variation.\n",
    "- Sphere: the two dimensional surface of a three dimensional sphere. This cannot be represented accurately in two dimensions without tearing. The sphere has been coloured with hue around the equator and black to white from the south to north pole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--bgm8BhcAA9"
   },
   "outputs": [],
   "source": [
    "## Just for kicks, we 10xed the samples compared to the original source code.  Cause we can.  \n",
    "sns.set(context=\"paper\", style=\"white\")\n",
    "\n",
    "blobs, blob_labels = datasets.make_blobs(\n",
    "    n_samples=5000, n_features=10, centers=5, random_state=42\n",
    ")\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits(n_class=10)\n",
    "wine = datasets.load_wine()\n",
    "swissroll, swissroll_labels = datasets.make_swiss_roll(\n",
    "    n_samples=10000, noise=0.1, random_state=42\n",
    ")\n",
    "sphere = np.random.normal(size=(600, 3))\n",
    "sphere = preprocessing.normalize(sphere)\n",
    "sphere_hsv = np.array(\n",
    "    [\n",
    "        (\n",
    "            (np.arctan2(c[1], c[0]) + np.pi) / (2 * np.pi),\n",
    "            np.abs(c[2]),\n",
    "            min((c[2] + 1.1), 1.0),\n",
    "        )\n",
    "        for c in sphere\n",
    "    ]\n",
    ")\n",
    "sphere_colors = np.array([hsv_to_rgb(*c) for c in sphere_hsv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "095gJwL6cABA"
   },
   "source": [
    "## Call your algorithms and define your iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LKhE2tZZcABA",
    "outputId": "09891bcc-1bc2-495e-a0db-316bd926311a"
   },
   "outputs": [],
   "source": [
    "## Change your parameters so that you can see how it affects your results\n",
    "nc = 2\n",
    "rs = 42\n",
    "nn = 30\n",
    "\n",
    "## Iterate through our decomposition algorithms TSVD, PCA, and UMAP\n",
    "reducers = [\n",
    "    (cuml.TruncatedSVD(n_components=nc,algorithm='full', random_state=rs)),\n",
    "    (cuml.TruncatedSVD(n_components=nc,algorithm='jacobi', random_state=rs)),\n",
    "    (cuml.PCA(n_components=nc,svd_solver='full',whiten=False, random_state=rs)),\n",
    "    (cuml.PCA(n_components=nc,svd_solver='jacobi',whiten=False, random_state=rs)),\n",
    "    (cuml.UMAP(n_neighbors=nn, init=\"spectral\")),\n",
    "    (cuml.TSNE(n_components = nc, method = 'barnes_hut')),\n",
    "]\n",
    "\n",
    "##  Iterate through your datasets\n",
    "test_data = [\n",
    "    (blobs, blob_labels),\n",
    "    (iris.data, iris.target),\n",
    "    (digits.data, digits.target),\n",
    "    (wine.data, wine.target),\n",
    "    (swissroll, swissroll_labels),\n",
    "    (sphere, sphere_colors),\n",
    "]\n",
    "\n",
    "## Name your data\n",
    "dataset_names = [\"Blobs\", \"Iris\", \"Digits\", \"Wine\", \"Swiss Roll\", \"Sphere\"]\n",
    "\n",
    "## Helper variables\n",
    "n_rows = len(test_data)\n",
    "n_cols = len(reducers)\n",
    "ax_index = 1\n",
    "ax_list = []\n",
    "\n",
    "## Size your plots\n",
    "plt.rcParams[\"figure.figsize\"] = [20,20]\n",
    "plt.subplots_adjust(\n",
    "    left=.2, right=10, bottom=.001, top=.96, wspace=.05, hspace=.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eej_AkgcABE"
   },
   "source": [
    "## Run your tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xhmo2qUKcABE"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for data, labels in test_data:\n",
    "    gdf=cudf.DataFrame.from_records(data) # skLearn data is a numpy ndarray, so we can just use \"from_records\" to put it into a cudf dataframe\"\n",
    "    for reducer in reducers:\n",
    "        start_time = time.time()\n",
    "        embedding = reducer.fit_transform(gdf)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        ax = plt.subplot(n_rows, n_cols, ax_index)\n",
    "        #print(embedding.T)\n",
    "        embedding_numpy = embedding.to_pandas().values\n",
    "        #pdb.set_trace()\n",
    "        if isinstance(labels[0], tuple):\n",
    "            ax.scatter(*embedding_numpy.T, s=10, c=labels, alpha=0.5)\n",
    "        else:\n",
    "            ax.scatter(\n",
    "                *embedding_numpy.T, s=10, c=labels, cmap=\"Spectral\", alpha=0.5\n",
    "            )\n",
    "        ax.text(\n",
    "            0.99,\n",
    "            0.01,\n",
    "            \"{:.2f} s\".format(elapsed_time),\n",
    "            transform=ax.transAxes,\n",
    "            size=14,\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "        ax_list.append(ax)\n",
    "        ax_index += 1\n",
    "plt.setp(ax_list, xticks=[], yticks=[])\n",
    "for i in np.arange(n_rows) * n_cols:\n",
    "    ax_list[i].set_ylabel(dataset_names[i // n_cols], size=16)\n",
    "for i in range(n_cols):\n",
    "    ax_list[i].set_xlabel(repr(reducers[i]).split(\".\")[0].split(\"(\")[0], size=16)\n",
    "    ax_list[i].xaxis.set_label_position(\"top\")\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NsK7pTE7xoDT",
    "outputId": "b3b7cc2c-b194-4450-c90e-765fef04ad21"
   },
   "outputs": [],
   "source": [
    "repr(reducers[2]).split(\".\")[0].split(\"(\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PC9Thw9ycABH"
   },
   "source": [
    "Checking out the images, you can see how different dimension reduction methods will cluster, represent your data, and how fast it will do it.  This enables you to pick the best one for your uses.  You can change `rs`, `nc`, `nn` to see how the decomposition changes using the visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BF8j3OkjcABI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rapids_decomposition_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "RAPIDS Stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
